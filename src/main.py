import asyncio
import argparse
from pathlib import Path
from typing import Dict, Any, Optional, List
from config.azure_config import AzureConfig
from models.ai_models import AIModels
from tools.tools import Tools
from raptor.raptor_setup import RaptorSetup
from agent.react_agent import create_react_agent
from llama_index.core.callbacks import CBEventType, CallbackManager
from llama_index.core.callbacks.base_handler import BaseCallbackHandler
from utils.token_counter import TokenCounter, create_token_counter
from PIL import Image
import io
import os
import sys
from utils.pdf_converter import convert_pdf_to_image
from utils.output_saver import save_output
import json
from datetime import datetime
from utils.raw_text_extractor import RawTextExtractor

class CustomCallbackHandler(BaseCallbackHandler):
    """Handler personnalis√© pour logger les √©v√©nements de l'agent"""
    
    def __init__(self) -> None:
        super().__init__([], [])
        print("\nüîÑ Initialisation du CustomCallbackHandler")
        self.steps = {
            "vision_analysis": "",
            "consistency_check": "",
            "dates_verification": "",
            "legislation": "",
            "clarifications": "",
            "compliance_analysis": "",
            "raw_text": ""
        }
        print("‚úÖ Steps initialis√©s :", self.steps.keys())
        self.current_action = None
        self.token_counter = None  # Sera d√©fini plus tard
        
    def set_token_counter(self, token_counter: TokenCounter) -> None:
        """D√©finir le compteur de tokens pour ce handler."""
        self.token_counter = token_counter
        
    def on_event_start(
        self,
        event_type: CBEventType,
        payload: Optional[Dict[str, Any]] = None,
        event_id: str = "",
        parent_id: str = "",
        **kwargs: Any,
    ) -> str:
        """Log le d√©but d'un √©v√©nement"""
        if event_type == CBEventType.FUNCTION_CALL and payload:
            tool_metadata = payload.get("tool", {})
            if hasattr(tool_metadata, "name"):
                self.current_action = tool_metadata.name
                print(f"‚úÖ Action courante mise √† jour: {self.current_action}")
                
                # D√©finir l'√©tape courante dans le compteur de tokens
                if self.token_counter:
                    if self.current_action == "analyze_vision":
                        self.token_counter.set_current_step("vision_analysis")
                    elif self.current_action == "verify_consistency":
                        self.token_counter.set_current_step("consistency_check")
                    elif self.current_action == "verify_dates":
                        self.token_counter.set_current_step("dates_verification")
                    elif self.current_action == "search_legislation":
                        self.token_counter.set_current_step("legislation_search")
                    elif self.current_action == "get_clarifications":
                        self.token_counter.set_current_step("clarifications")
                    elif self.current_action == "analyze_compliance":
                        self.token_counter.set_current_step("compliance_analysis")
                    elif self.current_action == "extract_raw_text":
                        self.token_counter.set_current_step("raw_text_extraction")
                    else:
                        self.token_counter.set_current_step("other")
        
        return event_id

    def on_event_end(
        self,
        event_type: CBEventType,
        payload: Optional[Dict[str, Any]] = None,
        event_id: str = "",
        **kwargs: Any,
    ) -> None:
        """Log la fin d'un √©v√©nement"""
        if event_type == CBEventType.FUNCTION_CALL and payload:
            if "function_call_response" in payload:
                print(f"\n{'='*50}")
                print(f"üìù Traitement de la r√©ponse pour l'action: {self.current_action}")
                response = str(payload["function_call_response"])
                
                # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
                if response.startswith("assistant:"):
                    response = response[len("assistant:"):].strip()
                
                # Stocker la r√©ponse selon l'action
                if self.current_action == "analyze_vision":
                    print("üíæ Sauvegarde de l'analyse visuelle...")
                    self.steps["vision_analysis"] = response
                elif self.current_action == "verify_consistency":
                    print("üíæ Sauvegarde de la v√©rification de coh√©rence...")
                    self.steps["consistency_check"] = response
                elif self.current_action == "verify_dates":
                    print("üíæ Sauvegarde de la v√©rification des dates...")
                    self.steps["dates_verification"] = response
                elif self.current_action == "search_legislation":
                    print("üíæ Sauvegarde de la l√©gislation...")
                    self.steps["legislation"] = response
                elif self.current_action == "get_clarifications":
                    print("üíæ Sauvegarde des clarifications...")
                    self.steps["clarifications"] = response
                elif self.current_action == "analyze_compliance":
                    print("üíæ Sauvegarde de l'analyse de conformit√©...")
                    self.steps["compliance_analysis"] = response
                elif self.current_action == "extract_raw_text":
                    print("üíæ Sauvegarde du texte brut...")
                    self.steps["raw_text"] = response
                
                print(f"{'='*50}\n")

    def start_trace(self, trace_id: Optional[str] = None) -> None:
        """D√©but d'une trace"""
        print(f"\nüìù D√©but de la trace: {trace_id}")

    def end_trace(
        self,
        trace_id: Optional[str] = None,
        trace_map: Optional[Dict[str, Any]] = None,
    ) -> None:
        """Fin d'une trace"""
        print(f"üìù Fin de la trace: {trace_id}\n")
        
        # Afficher les statistiques de tokens √† la fin de l'analyse
        if self.token_counter:
            self.token_counter.print_step_stats()
            self.token_counter.save_stats()

def initialize_system(callback_handler):
    """
    Initialise les composants du syst√®me d'analyse
    
    Args:
        callback_handler: Gestionnaire d'√©v√©nements
        
    Returns:
        tuple: (azure_config, ai_models, tools, raptor_setup)
    """
    print("\nüîÑ Initialisation du syst√®me...")
    
    # Configuration
    azure_config = AzureConfig()
    
    # Mod√®les IA
    ai_models = AIModels(azure_config)
    
    # Base de connaissances Raptor
    raptor_setup = RaptorSetup(ai_models=ai_models)
    
    # Outils d'analyse
    tools = Tools(llm=ai_models.llm, raptor=raptor_setup)
    
    print("‚úÖ Syst√®me initialis√© avec succ√®s\n")
    
    return azure_config, ai_models, tools, raptor_setup

async def analyze_image(image_path: str, agent = None) -> None:
    """
    Analyse une image ou un PDF avec l'agent React
    
    Args:
        image_path: Chemin vers l'image ou le PDF √† analyser
        agent: Agent React pr√©configurer (optionnel)
    """
    # Valider et pr√©parer le chemin du fichier
    path = validate_image_path(image_path)
    if not path:
        print(f"‚ùå Fichier invalide : {image_path}")
        return

    # Convertir le PDF en image si n√©cessaire
    if Path(path).suffix.lower() == '.pdf':
        try:
            print(f"üîÑ Conversion du PDF en image...")
            path = convert_pdf_to_image(path)
            print(f"‚úÖ PDF converti en image : {path}")
        except Exception as e:
            print(f"‚ùå Erreur lors de la conversion du PDF : {e}")
            return
    
    # Si aucun agent n'est fourni, en cr√©er un nouveau
    if agent is None:
        # Initialiser le syst√®me
        callback_handler = CustomCallbackHandler()
        azure_config, ai_models, tools, raptor_setup = initialize_system(callback_handler)
        
        # Cr√©er un CallbackManager avec notre handler
        callback_manager = CallbackManager([callback_handler])
        
        # Ajouter le compteur de tokens au gestionnaire de callbacks
        token_counter = create_token_counter(verbose=True, save_dir="stats/tokens")
        callback_manager.add_handler(token_counter)
        
        # Connecter le compteur de tokens au callback_handler
        callback_handler.set_token_counter(token_counter)
        
        # Cr√©er l'agent
        agent = create_react_agent(
            ai_models=ai_models, 
            tools=tools, 
            callback_manager=callback_manager,
            verbose=True
        )

    start_time = datetime.now()
    print(f"‚è±Ô∏è  D√©but de l'analyse : {start_time.strftime('%H:%M:%S')}")
    
    # Ex√©cuter l'analyse
    try:
        # Essayer d'abord avec `aquery` qui est souvent utilis√© dans les versions r√©centes
        if hasattr(agent, 'aquery'):
            raw_response = await asyncio.wait_for(agent.aquery(path), timeout=300)  # Timeout de 5 minutes
        # Sinon essayer avec `achat` 
        elif hasattr(agent, 'achat'):
            raw_response = await asyncio.wait_for(agent.achat(path), timeout=300)  # Timeout de 5 minutes
        # Ou essayer avec `run` en mode synchrone si n√©cessaire
        elif hasattr(agent, 'run'):
            raw_response = agent.run(path)  # Pas de timeout pour run synchrone
        else:
            raise AttributeError("L'agent ne poss√®de aucune m√©thode appropri√©e pour l'ex√©cution (aquery, achat, run)")
        
        # Convertir la r√©ponse en cha√Æne de caract√®res
        if hasattr(raw_response, 'response'):
            response = raw_response.response
        elif hasattr(raw_response, 'result'):
            response = raw_response.result
        elif hasattr(raw_response, 'output'):
            response = raw_response.output
        elif hasattr(raw_response, 'message'):
            response = raw_response.message
        elif isinstance(raw_response, dict) and 'response' in raw_response:
            response = raw_response['response']
        elif isinstance(raw_response, str):
            response = raw_response
        else:
            # En dernier recours, convertir en cha√Æne de caract√®res
            response = str(raw_response)
            print(f"‚ö†Ô∏è Conversion de l'objet Response en cha√Æne - type original: {type(raw_response)}")
    except Exception as e:
        print(f"‚ùå Erreur lors de l'ex√©cution de l'agent: {str(e)}")
        response = f"Erreur d'analyse: {str(e)}"
    
    end_time = datetime.now()
    duration = end_time - start_time
    print(f"‚è±Ô∏è  Fin de l'analyse : {end_time.strftime('%H:%M:%S')} (dur√©e: {duration})")
    
    # Sauvegarder le r√©sultat
    try:
        output_path = save_output(path, {
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "steps": {
                "vision_analysis": callback_handler.steps["vision_analysis"],
                "consistency_check": callback_handler.steps["consistency_check"],
                "dates_verification": callback_handler.steps["dates_verification"],
                "legislation": callback_handler.steps["legislation"],
                "clarifications": callback_handler.steps["clarifications"],
                "compliance_analysis": callback_handler.steps["compliance_analysis"],
                "raw_text": callback_handler.steps["raw_text"]
            },
            "final_response": response
        })
        print(f"üíæ R√©sultat sauvegard√© : {output_path}")
    except Exception as e:
        print(f"‚ùå Erreur lors de la sauvegarde du r√©sultat : {e}")
    
    print("üèÅ Analyse termin√©e")

def validate_image_path(path: str) -> str:
    """
    Valide le chemin de l'image ou du PDF
    
    Args:
        path: Chemin √† valider
        
    Returns:
        str: Chemin valid√©
        
    Raises:
        ArgumentTypeError: Si le chemin n'est pas valide
    """
    file_path = Path(path)
    if not file_path.exists():
        raise argparse.ArgumentTypeError(f"Le fichier {path} n'existe pas")
    if not file_path.is_file():
        raise argparse.ArgumentTypeError(f"{path} n'est pas un fichier")
    if file_path.suffix.lower() not in ['.jpg', '.jpeg', '.png', '.pdf']:
        raise argparse.ArgumentTypeError(f"{path} n'est pas un format support√© (formats accept√©s : jpg, jpeg, png, pdf)")
    return str(file_path.absolute())

def get_files_to_analyze(path: str, recursive: bool = False) -> List[str]:
    """
    R√©cup√®re la liste des fichiers √† analyser
    
    Args:
        path: Chemin vers le fichier ou dossier
        recursive: Explorer r√©cursivement les sous-dossiers
        
    Returns:
        List[str]: Liste des chemins de fichiers √† analyser
    """
    path_obj = Path(path)
    supported_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp', '.pdf', '.tiff', '.webp']
    files = []
    
    if path_obj.is_file():
        # C'est un fichier unique
        if path_obj.suffix.lower() in supported_extensions:
            print(f"‚úÖ Fichier √† analyser: {path_obj}")
            return [str(path_obj)]
        else:
            print(f"‚ö†Ô∏è Format de fichier non support√©: {path_obj}")
            return []
    
    elif path_obj.is_dir():
        # C'est un dossier
        print(f"üìÇ Analyse du dossier: {path_obj}")
        
        # R√©cup√©rer tous les fichiers du dossier avec les extensions support√©es
        if recursive:
            for ext in supported_extensions:
                files.extend(list(path_obj.glob(f"**/*{ext}")))
        else:
            for ext in supported_extensions:
                files.extend(list(path_obj.glob(f"*{ext}")))
                
        files = [str(f) for f in files]
        
        if files:
            print(f"‚úÖ {len(files)} fichiers trouv√©s dans le dossier")
        else:
            print(f"‚ö†Ô∏è Aucun fichier support√© trouv√© dans le dossier")
            
        return files
    
    else:
        print(f"‚ùå Chemin invalide: {path_obj}")
        return []

async def analyze_files(files: List[str]) -> None:
    """
    Analyse une liste de fichiers
    
    Args:
        files: Liste des chemins de fichiers √† analyser
    """
    if not files:
        print("‚ö†Ô∏è Aucun fichier √† analyser")
        return
        
    print(f"üîç Analyse de {len(files)} fichier(s)...")
    
    # Initialiser le syst√®me
    callback_handler = CustomCallbackHandler()
    azure_config, ai_models, tools, raptor_setup = initialize_system(callback_handler)
    
    # Cr√©er un CallbackManager avec notre handler
    callback_manager = CallbackManager([callback_handler])
    
    # Ajouter le compteur de tokens au gestionnaire de callbacks
    token_counter = create_token_counter(verbose=True, save_dir="stats/tokens")
    callback_manager.add_handler(token_counter)
    
    # Connecter le compteur de tokens au callback_handler
    callback_handler.set_token_counter(token_counter)
    
    # Cr√©er l'agent
    agent = create_react_agent(
        ai_models=ai_models, 
        tools=tools, 
        callback_manager=callback_manager,
        verbose=True
    )
    
    # Analyser chaque fichier
    for file_path in files:
        try:
            print(f"\nüìÑ Analyse du fichier: {file_path}")
            await analyze_image(file_path)
        except Exception as e:
            print(f"‚ùå Erreur lors de l'analyse de {file_path}: {str(e)}")
            
    print("\n‚úÖ Analyse termin√©e")

def test_text_extraction(files: List[str], tools: Tools, mode: str = "docling", ocr_engine: str = "tesseract") -> None:
    """
    Teste la fonctionnalit√© d'extraction de texte sur les fichiers sp√©cifi√©s
    
    Args:
        files: Liste des fichiers √† analyser
        tools: Instance des outils avec la fonctionnalit√© d'extraction de texte
        mode: Mode d'extraction ('docling', 'gpt4v', 'azure_cv')
        ocr_engine: Moteur OCR √† utiliser avec Docling ('tesseract', 'easyocr', 'rapidocr', 'tesseract_api')
    """
    print(f"\nüß™ Test de l'extraction de texte sur {len(files)} fichier(s)...")
    print(f"üìä Mode: {mode}, Moteur OCR: {ocr_engine if mode == 'docling' else 'N/A'}")
    
    for file_path in files:
        print(f"\nüìÑ Fichier: {file_path}")
        try:
            extracted_text = tools.extract_text_from_image(file_path, mode, ocr_engine)
            print("\nüìù Texte extrait:")
            print("-" * 50)
            print(extracted_text)
            print("-" * 50)
        except Exception as e:
            print(f"‚ùå Erreur lors de l'extraction de texte: {str(e)}")

def extract_raw_text(files: List[str], method: str = "auto") -> None:
    """
    Utilise le nouvel extracteur pour obtenir le texte brut des images sans corrections
    
    Args:
        files: Liste des fichiers √† analyser
        method: M√©thode d'extraction √† utiliser ('tesseract', 'easyocr', 'auto', 'gpt_vision')
    """
    print(f"\nüîç Extraction de texte BRUT sur {len(files)} fichier(s)...")
    print(f"üìä M√©thode: {method}")
    
    # Si nous utilisons GPT Vision, utiliser les outils de l'application principale
    if method == "gpt_vision":
        # Initialiser le syst√®me
        callback_handler = CustomCallbackHandler()
        azure_config, ai_models, tools, raptor_setup = initialize_system(callback_handler)
        
        for file_path in files:
            print(f"\nüìÑ Fichier: {file_path}")
            
            try:
                # Extraire le texte brut avec GPT Vision
                extracted_text = tools.extract_raw_text_with_vision(file_path)
                
                print("\n===== TEXTE EXTRAIT AVEC GPT VISION =====")
                print("-" * 50)
                print(extracted_text if extracted_text else "[Aucun texte extrait]")
                print("-" * 50)
                
            except Exception as e:
                print(f"‚ùå Erreur lors de l'extraction de texte avec GPT Vision: {str(e)}")
        
        return
    
    # Initialiser l'extracteur de texte brut traditionnel pour les autres m√©thodes
    extractor = RawTextExtractor()
    
    for file_path in files:
        print(f"\nüìÑ Fichier: {file_path}")
        
        try:
            # Extraire le texte brut
            results = extractor.extract_raw_text(file_path, method)
            
            if not results:
                print("‚ùå Aucun texte extrait")
                continue
                
            # Afficher les r√©sultats
            for method_name, text in results.items():
                print(f"\n===== TEXTE EXTRAIT AVEC {method_name.upper()} =====")
                print("-" * 50)
                print(text if text else "[Aucun texte extrait]")
                print("-" * 50)
                
                # Sauvegarder le r√©sultat
                try:
                    # Cr√©er le chemin de sortie
                    output_dir = Path("outputs") / "raw_text"
                    output_dir.mkdir(parents=True, exist_ok=True)
                    
                    # Nom du fichier de sortie
                    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                    output_file = output_dir / f"{Path(file_path).stem}_{method_name}_{timestamp}.txt"
                    
                    # √âcrire le texte extrait
                    with open(output_file, "w", encoding="utf-8") as f:
                        f.write(text)
                    
                    print(f"üíæ Texte sauvegard√©: {output_file}")
                    
                except Exception as e:
                    print(f"‚ùå Erreur lors de la sauvegarde du texte: {str(e)}")
            
        except Exception as e:
            print(f"‚ùå Erreur lors de l'extraction de texte: {str(e)}")

def parse_args():
    """Parse les arguments de la ligne de commande"""
    parser = argparse.ArgumentParser(description="Analyse de publicit√©s pour conformit√© l√©gale")
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument("--files", nargs="+", help="Chemins vers les fichiers √† analyser")
    group.add_argument("--dir", help="Chemin vers le r√©pertoire contenant les fichiers √† analyser")
    parser.add_argument("--test_text_extraction", action="store_true", 
                        help="Active uniquement le test d'extraction de texte sans analyse compl√®te")
    parser.add_argument("--extract_raw_text", action="store_true",
                        help="Extrait le texte brut des images sans corrections")
    parser.add_argument("--mode", choices=["docling", "gpt4v", "azure_cv"], default="docling",
                        help="Mode d'extraction de texte (docling, gpt4v, azure_cv)")
    parser.add_argument("--ocr", choices=["tesseract", "easyocr", "rapidocr", "tesseract_api"], 
                        default="tesseract", help="Moteur OCR √† utiliser avec Docling")
    parser.add_argument("--method", choices=["tesseract", "easyocr", "auto", "gpt_vision"], default="auto",
                        help="M√©thode d'extraction de texte brut")
    
    return parser.parse_args()

def main():
    """Point d'entr√©e principal de l'application"""
    args = parse_args()
    
    if args.files or args.dir:
        callback_handler = CustomCallbackHandler()
        azure_config, ai_models, tools, raptor_setup = initialize_system(callback_handler)
        
        files_to_analyze = get_files_to_analyze(args.dir if args.dir else args.files[0])
        
        if args.test_text_extraction:
            test_text_extraction(files_to_analyze, tools, args.mode, args.ocr)
        elif args.extract_raw_text:
            extract_raw_text(files_to_analyze, args.method)
        else:
            asyncio.run(analyze_files(files_to_analyze))
    else:
        print("‚ùå Aucun fichier ou r√©pertoire sp√©cifi√©. Utilisez --file ou --dir.")

if __name__ == "__main__":
    main() 