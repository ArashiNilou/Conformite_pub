import base64
from typing import Dict, Any, List
from llama_index.llms.azure_openai import AzureOpenAI
from llama_index.core.schema import Document, MediaResource
from llama_index.core.llms import ChatMessage, ImageBlock, TextBlock, MessageRole
from llama_index.core.tools import BaseTool, FunctionTool
from prompts.prompts import description_prompt, legal_prompt, clarifications_prompt, consistency_prompt, raw_text_extraction_prompt
from raptor.raptor_setup import RaptorSetup
from datetime import datetime
from utils.output_saver import OutputSaver
from utils.text_extractor import TextExtractor
from utils.logo_product_matcher import LogoProductMatcher
import os
from pathlib import Path
import re
import calendar

class Tools:
    """Collection des outils disponibles pour l'analyse de publicit√©"""
    def __init__(self, llm: AzureOpenAI, raptor: RaptorSetup):
        self.llm = llm
        self.raptor = raptor
        self._tools = self._create_tools()
        self.vision_result = None
        self.legislation = None
        self.raw_text = None
        self.output_saver = OutputSaver()
        self.text_extractor = TextExtractor()
        self.extracted_text = None
        self.logo_product_matcher = LogoProductMatcher()
        self.product_logo_inconsistencies = []
        # Dictionnaire pour r√©f√©rence correcte des jours de la semaine
        self.correct_days = {
            "lundi": "lundi",
            "mardi": "mardi", 
            "mercredi": "mercredi", 
            "jeudi": "jeudi", 
            "vendredi": "vendredi", 
            "samedi": "samedi", 
            "dimanche": "dimanche"
        }
    
    def _create_tools(self) -> list[BaseTool]:
        """Cr√©e la liste des outils disponibles pour l'agent"""
        return [
            FunctionTool.from_defaults(
                fn=self.extract_raw_text_for_agent,
                name="extract_raw_text",
                description="Extrait le texte brut d'une image publicitaire sans aucune modification ou correction. √Ä utiliser en PREMIER, avant toute autre analyse.",
            ),
            FunctionTool.from_defaults(
                fn=self.analyze_vision,
                name="analyze_vision",
                description="Analyse une image publicitaire et fournit une description d√©taill√©e structur√©e. Utilisez cet outil APR√àS l'extraction du texte brut.",
            ),
            FunctionTool.from_defaults(
                fn=self.verify_consistency,
                name="verify_consistency",
                description="V√©rifie la coh√©rence des informations (orthographe, adresse, t√©l√©phone, email, url) apr√®s l'analyse visuelle.",
            ),
            FunctionTool.from_defaults(
                fn=self.verify_product_logo_consistency,
                name="verify_product_logo_consistency",
                description="V√©rifie la coh√©rence entre les logos et les produits mentionn√©s dans la publicit√©.",
            ),
            FunctionTool.from_defaults(
                fn=self.verify_dates,
                name="verify_dates",
                description="V√©rifie la coh√©rence des dates et des jours de la semaine mentionn√©s dans la publicit√©. V√©rifie √©galement si les dates sont futures ou pass√©es.",
            ),
            FunctionTool.from_defaults(
                fn=self.search_legislation,
                name="search_legislation",
                description="Recherche la l√©gislation applicable en fonction de la description de l'image. √Ä utiliser apr√®s analyze_vision.",
            ),
            FunctionTool.from_defaults(
                fn=self.get_clarifications,
                name="get_clarifications",
                description="Obtient des clarifications sp√©cifiques sur des aspects de la publicit√© en se basant sur la vision et la l√©gislation.",
            ),
            FunctionTool.from_defaults(
                fn=self.analyze_compliance,
                name="analyze_compliance",
                description="Analyse finale de la conformit√© de la publicit√© en combinant tous les r√©sultats pr√©c√©dents.",
            ),
        ]
    
    @property
    def tools(self) -> list[BaseTool]:
        """Retourne la liste des outils disponibles"""
        return self._tools

    def analyze_vision(self, image_path: str) -> str:
        """
        Analyse une image publicitaire avec GPT-4o
        Args:
            image_path: Chemin vers l'image √† analyser
        Returns:
            str: Description d√©taill√©e structur√©e de l'image
        """
        print(f"\nüñºÔ∏è Analyse de l'image: {image_path}")
        
        # V√©rifier si l'analyse a d√©j√† √©t√© initialis√©e (par l'extraction de texte brut)
        if not self.output_saver.is_analysis_in_progress():
            self.output_saver.start_new_analysis(image_path)
        
        with open(image_path, "rb") as image_file:
            img_data = base64.b64encode(image_file.read())
        
        self._last_image_data = img_data  # Garder l'image en m√©moire
        image_document = Document(image_resource=MediaResource(data=img_data))
        
        # Pr√©parer un prompt qui inclut le texte brut d√©j√† extrait
        enhanced_prompt = description_prompt
        if hasattr(self, 'raw_text') and self.raw_text:
            enhanced_prompt = f"""Le texte brut suivant a d√©j√† √©t√© extrait de l'image. Utilisez-le comme r√©f√©rence pour votre analyse mais NE LE RECOPIEZ PAS int√©gralement:

TEXTE BRUT D√âJ√Ä EXTRAIT:
----------
{self.raw_text}
----------

{description_prompt}"""
        
        msg = ChatMessage(
            role=MessageRole.USER,
            blocks=[
                TextBlock(text=enhanced_prompt),
                ImageBlock(image=image_document.image_resource.data),
            ],
        )

        response = self.llm.chat(messages=[msg])
        result = str(response)
        
        # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
        if result.startswith("assistant:"):
            result = result[len("assistant:"):].strip()
            
        self.vision_result = result
        
        self.output_saver.save_vision_result(self.vision_result)
        
        return self.vision_result

    def check_weekday_spelling(self, text: str) -> list:
        """
        V√©rifie l'orthographe des jours de la semaine dans le texte
        
        Args:
            text: Texte √† v√©rifier
            
        Returns:
            list: Liste des erreurs d'orthographe d√©tect√©es au format JSON
        """
        if not text:
            return []
        
        # Liste des orthographes correctes
        self.correct_days = {
            "lundi": "lundi",
            "mardi": "mardi",
            "mercredi": "mercredi",
            "jeudi": "jeudi",
            "vendredi": "vendredi",
            "samedi": "samedi",
            "dimanche": "dimanche"
        }
        
        # Liste des fautes d'orthographe courantes
        common_misspellings = {
            "lumdi": "lundi",
            "marid": "mardi",
            "mecredis": "mercredi",
            "mercredis": "mercredi",
            "jedi": "jeudi",
            "jeudis": "jeudi",
            "venredi": "vendredi",
            "venredis": "vendredi",
            "vendedi": "vendredi",
            "vendredy": "vendredi",
            "samedis": "samedi",
            "dimanches": "dimanche"
        }
        
        # Erreurs d√©tect√©es
        errors = []
        
        # V√©rification des orthographes incorrectes
        for misspelling, correction in common_misspellings.items():
            # Utiliser une expression r√©guli√®re pour rechercher le mot avec fronti√®res de mot
            pattern = re.compile(r'\b' + re.escape(misspelling) + r'\b', re.IGNORECASE)
            matches = pattern.finditer(text)
            
            for match in matches:
                misspelled_text = match.group(0)
                errors.append({
                    "text": misspelled_text,
                    "correction": correction if misspelled_text.islower() else correction.capitalize(),
                    "position": match.start(),
                    "context": text[max(0, match.start()-15):min(len(text), match.end()+15)]
                })
        
        # V√©rification suppl√©mentaire pour les probl√®mes de majuscule au milieu de phrase
        for day, correct_spelling in self.correct_days.items():
            # Rechercher le jour en minuscule au d√©but d'une phrase ou apr√®s une ponctuation
            pattern = re.compile(r'(?:^|[.!?]\s+)' + re.escape(day) + r'\b', re.IGNORECASE)
            matches = pattern.finditer(text)
            
            for match in matches:
                found_day = match.group(0).strip().lstrip('.!?').strip()
                # V√©rifier si le premier caract√®re est en minuscule alors qu'il devrait √™tre en majuscule
                if found_day and found_day[0].islower():
                    errors.append({
                        "text": found_day,
                        "correction": found_day.capitalize(),
                        "position": match.start(),
                        "context": text[max(0, match.start()-15):min(len(text), match.end()+15)],
                        "type": "majuscule_manquante"
                    })
            
            # Rechercher le jour en majuscule au milieu d'une phrase
            pattern = re.compile(r'(?<![.!?]\s+)\b' + re.escape(day).capitalize() + r'\b')
            matches = pattern.finditer(text)
            
            for match in matches:
                # V√©rifier que ce n'est pas en d√©but de ligne ou de phrase
                if match.start() > 0 and text[match.start()-1].isalpha():
                    errors.append({
                        "text": match.group(0),
                        "correction": match.group(0).lower(),
                        "position": match.start(),
                        "context": text[max(0, match.start()-15):min(len(text), match.end()+15)],
                        "type": "majuscule_inappropriee"
                    })
        
        return errors

    def calculate_levenshtein_distance(self, s1: str, s2: str) -> int:
        """
        Calcule la distance de Levenshtein (distance d'√©dition) entre deux cha√Ænes.
        Mesure le nombre minimum d'op√©rations (insertions, suppressions, substitutions)
        n√©cessaires pour transformer une cha√Æne en une autre.
        
        Args:
            s1: Premi√®re cha√Æne
            s2: Deuxi√®me cha√Æne
            
        Returns:
            int: Distance de Levenshtein
        """
        if len(s1) < len(s2):
            return self.calculate_levenshtein_distance(s2, s1)
        
        if len(s2) == 0:
            return len(s1)
        
        previous_row = range(len(s2) + 1)
        for i, c1 in enumerate(s1):
            current_row = [i + 1]
            for j, c2 in enumerate(s2):
                insertions = previous_row[j + 1] + 1
                deletions = current_row[j] + 1
                substitutions = previous_row[j] + (c1 != c2)
                current_row.append(min(insertions, deletions, substitutions))
            previous_row = current_row
        
        return previous_row[-1]

    def check_spelling(self, text: str) -> list:
        """
        V√©rifie l'orthographe de tous les mots dans un texte
        
        Args:
            text: Texte brut extrait de l'image
            
        Returns:
            list: Liste des fautes d'orthographe d√©tect√©es
        """
        print("\nüîç V√©rification de l'orthographe de tous les mots...")
        
        if not text:
            return []
            
        # Liste pour stocker les erreurs trouv√©es
        spelling_errors = []
        
        try:
            # V√©rification des jours de la semaine (gardons cette partie sp√©cifique)
            weekday_errors = self.check_weekday_spelling(text)
            spelling_errors.extend(weekday_errors)
            
            # Rechercher les erreurs communes dans le dictionnaire de corrections
            common_errors = {
                # Mots g√©n√©raux
                "publicite": "publicit√©",
                "telefone": "t√©l√©phone", 
                "telphone": "t√©l√©phone",
                "adrese": "adresse",
                "addresse": "adresse",
                "mangez": "manger",
                "bouger": "bouger",
                "ofre": "offre",
                "promocion": "promotion",
                "remise": "remise",
                "prix": "prix",
                "magazin": "magasin",
                "boutique": "boutique",
                "ouver": "ouvert",
                "ferm√©": "ferm√©",
                
                # Erreurs courantes en fran√ßais
                "chauque": "chaque",
                "plusieur": "plusieurs", 
                "baucoup": "beaucoup",
                "maintenent": "maintenant",
                "aujourdhui": "aujourd'hui",
                "corespond": "correspond",
                "necessite": "n√©cessite",
                "malheuresement": "malheureusement",
                "definitivment": "d√©finitivement",
                "notament": "notamment",
                "apareil": "appareil",
                "aparence": "apparence",
                "apartement": "appartement",
                "apeller": "appeler",
                "aplication": "application",
                "aprendre": "apprendre",
                "apres": "apr√®s",
                "ateur": "auteur",
                "batiment": "b√¢timent",
                "bibliotheque": "biblioth√®que",
                "biensur": "bien s√ªr",
                "bientot": "bient√¥t",
                "bizare": "bizarre",
                "boujour": "bonjour",
                "ceuillir": "cueillir",
                "chaqu'un": "chacun",
                "cherir": "ch√©rir",
                "conaitre": "conna√Ætre",
                "conaissance": "connaissance",
                "defois": "des fois",
                "deja": "d√©j√†",
                "dailleur": "d'ailleurs",
                "dailleurs": "d'ailleurs",
                "daccord": "d'accord",
                "dificult√©": "difficult√©",
                "excelent": "excellent",
                "exercise": "exercice",
                "interresant": "int√©ressant",
                "mechant": "m√©chant",
                "parcontre": "par contre",
                "peutetre": "peut-√™tre",
                "plusieures": "plusieurs",
                "pres": "pr√®s",
                "repondre": "r√©pondre",
                "reponce": "r√©ponse",
                "vraiement": "vraiment",
                "voyanture": "voyante"
            }
            
            # Dictionnaire de mots fran√ßais corrects pour r√©f√©rence
            french_words = set(common_errors.values())
            french_words.update(self.correct_days.values())
            # Ajouter d'autres mots fran√ßais courants
            french_words.update([
                "le", "la", "les", "un", "une", "des", "et", "ou", "√†", "au", "aux", "du", "des",
                "ce", "cette", "ces", "mon", "ma", "mes", "ton", "ta", "tes", "son", "sa", "ses",
                "notre", "nos", "votre", "vos", "leur", "leurs", "je", "tu", "il", "elle", "nous",
                "vous", "ils", "elles", "qui", "que", "quoi", "dont", "o√π", "comment", "pourquoi",
                "quand", "√™tre", "avoir", "faire", "dire", "aller", "voir", "savoir", "pouvoir",
                "vouloir", "falloir", "valoir", "prendre", "mettre", "passer", "devoir", "venir",
                "tenir", "mais", "ou", "et", "donc", "or", "ni", "car", "si", "grand", "petit",
                "beau", "joli", "bon", "mauvais", "vieux", "jeune", "nouveau", "dernier", "premier",
                "tout", "chaque", "certain", "m√™me", "autre", "tel", "quel", "quelque", "ceci", "cela",
                "rien", "personne", "quelqu'un", "chacun", "aucun", "nul", "tous", "plusieurs"
            ])
            
            # Rechercher les erreurs communes dans le texte
            for incorrect, correct in common_errors.items():
                matches = re.finditer(r'\b' + re.escape(incorrect) + r'\b', text.lower())
                for match in matches:
                    original_word = text[match.start():match.end()]
                    if original_word.lower() == incorrect:  # V√©rifier que c'est bien le mot incorrect
                        # D√©terminer la casse du mot correct en fonction du mot original
                        if original_word.isupper():
                            corrected = correct.upper()
                        elif original_word[0].isupper():
                            corrected = correct.capitalize()
                        else:
                            corrected = correct
                            
                        spelling_errors.append({
                            "incorrect": original_word,
                            "correct": corrected,
                            "position": match.start()
                        })
            
            # Analyser tous les mots du texte pour trouver d'autres erreurs potentielles
            words = re.findall(r'\b[a-zA-Z√Ä-√ø]{3,}\b', text)  # Mots d'au moins 3 lettres
            
            for word in words:
                # Ignorer les mots d√©j√† identifi√©s comme incorrects
                if any(error["incorrect"].lower() == word.lower() for error in spelling_errors):
                    continue
                
                word_lower = word.lower()
                
                # Ignorer les mots corrects d√©j√† connus
                if word_lower in french_words:
                    continue
                
                # Rechercher le mot le plus proche dans notre dictionnaire
                min_distance = float('inf')
                closest_word = None
                
                # Ne v√©rifier que les mots de longueur similaire pour optimiser
                for correct_word in french_words:
                    # Ne consid√©rer que les mots dont la longueur est proche
                    if abs(len(word_lower) - len(correct_word)) > 2:
                        continue
                    
                    # Calculer la distance de Levenshtein
                    distance = self.calculate_levenshtein_distance(word_lower, correct_word)
                    
                    # Normaliser la distance par rapport √† la longueur du mot
                    normalized_distance = distance / max(len(word_lower), len(correct_word))
                    
                    # Si la distance est faible (mot similaire) et meilleure que pr√©c√©demment
                    if normalized_distance < 0.25 and distance < min_distance:
                        min_distance = distance
                        closest_word = correct_word
                
                # Si on a trouv√© un mot similaire, consid√©rer comme une erreur
                if closest_word and min_distance <= 2:  # Max 2 op√©rations d'√©dition
                    # D√©terminer la casse du mot correct en fonction du mot original
                    if word.isupper():
                        corrected = closest_word.upper()
                    elif word[0].isupper():
                        corrected = closest_word.capitalize()
                    else:
                        corrected = closest_word
                    
                    # Trouver la position dans le texte
                    positions = [m.start() for m in re.finditer(r'\b' + re.escape(word) + r'\b', text)]
                    for position in positions:
                        spelling_errors.append({
                            "incorrect": word,
                            "correct": corrected,
                            "position": position,
                            "confidence": 1 - (min_distance / max(len(word), len(closest_word)))
                        })
            
            # Tri par position dans le texte et suppression des doublons
            spelling_errors.sort(key=lambda x: x["position"])
            
            # Supprimer les doublons (garder seulement la premi√®re occurrence)
            unique_errors = []
            seen = set()
            for error in spelling_errors:
                key = (error["incorrect"].lower(), error["position"])
                if key not in seen:
                    seen.add(key)
                    unique_errors.append(error)
            
            spelling_errors = unique_errors
            
            # Afficher le r√©sultat
            if spelling_errors:
                print(f"‚ö†Ô∏è {len(spelling_errors)} fautes d'orthographe d√©tect√©es:")
                for error in spelling_errors[:10]:  # Limiter l'affichage aux 10 premi√®res erreurs
                    confidence_info = f" (confiance: {error['confidence']:.2%})" if 'confidence' in error else ""
                    print(f"  - '{error['incorrect']}' devrait √™tre '{error['correct']}'{confidence_info}")
                if len(spelling_errors) > 10:
                    print(f"  - ... et {len(spelling_errors) - 10} autres fautes")
            else:
                print("‚úÖ Aucune faute d'orthographe d√©tect√©e")
                
            return spelling_errors
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la v√©rification orthographique: {str(e)}")
            return spelling_errors  # Retourner les erreurs trouv√©es jusqu'√† pr√©sent

    def verify_consistency(self, vision_result: str) -> str:
        """
        V√©rification de la coh√©rence des informations sur l'image
        
        Args:
            vision_result: R√©sultat de l'analyse visuelle
            
        Returns:
            str: Rapport de v√©rification des coh√©rences
        """
        print("\nüîç V√©rification de la coh√©rence...")
        
        if not hasattr(self, 'raw_text') or not self.raw_text:
            raise ValueError("Vous devez d'abord extraire le texte brut de l'image")
        
        # Stocker les r√©sultats pr√©c√©dents
        self.vision_result = vision_result
        
        # Obtenir la date actuelle au format fran√ßais
        current_date = datetime.now().strftime("%d/%m/%Y")
        
        # V√©rifier l'orthographe des jours de la semaine
        spelling_errors = self.check_weekday_spelling(self.raw_text)
        
        # V√©rifier les prix et r√©ductions
        price_errors = self.check_price_consistency(self.raw_text)
        
        # Pr√©parer la section des erreurs d'orthographe
        spelling_errors_section = ""
        if spelling_errors:
            spelling_errors_section = "\nERREURS D'ORTHOGRAPHE D√âTECT√âES (√† inclure dans votre analyse):\n"
            for i, error in enumerate(spelling_errors, 1):
                if "type" in error and error["type"] == "majuscule_manquante":
                    spelling_errors_section += f"{i}. ERREUR DE MAJUSCULE: '{error['text']}' devrait s'√©crire '{error['correction']}' en d√©but de phrase\n"
                elif "type" in error and error["type"] == "majuscule_inappropriee":
                    spelling_errors_section += f"{i}. ERREUR DE MAJUSCULE: '{error['text']}' devrait s'√©crire '{error['correction']}' en milieu de phrase\n"
                else:
                    spelling_errors_section += f"{i}. ERREUR D'ORTHOGRAPHE: '{error['text']}' devrait s'√©crire '{error['correction']}' (contexte: '{error['context']}')\n"
        
        # Pr√©parer la section des erreurs de prix
        price_errors_section = ""
        if price_errors:
            price_errors_section = "\nINCOH√âRENCES DE PRIX D√âTECT√âES (√† inclure obligatoirement dans votre analyse):\n"
            for i, error in enumerate(price_errors, 1):
                if error["type"] == "prix_sup√©rieur" or error["type"] == "prix_sup√©rieur_avec_r√©duction":
                    price_errors_section += f"{i}. ERREUR CRITIQUE: Le prix apr√®s r√©duction ({error['prix_r√©duit']}‚Ç¨) est SUP√âRIEUR au prix initial ({error['prix_initial']}‚Ç¨) dans '{error['texte_original']}'\n"
                elif error["type"] == "calcul_incorrect":
                    price_errors_section += f"{i}. ERREUR DE CALCUL: Pour une r√©duction de {error['pourcentage_r√©duction']}% sur {error['prix_initial']}‚Ç¨, le prix affich√© est {error['prix_affich√©']}‚Ç¨ alors qu'il devrait √™tre {error['prix_calcul√©']}‚Ç¨\n"
                elif error["type"] == "prix_barr√©_incoh√©rent":
                    price_errors_section += f"{i}. ERREUR CRITIQUE: Le prix r√©duit ({error['prix_r√©duit']}‚Ç¨) est SUP√âRIEUR au prix barr√© initial ({error['prix_initial']}‚Ç¨)\n"
        
        # Pr√©parer la section du texte brut
        raw_text_section = "TEXTE BRUT EXTRAIT DE L'IMAGE (r√©f√©rence exacte pour la v√©rification):\n\n"
        raw_text_section += self.raw_text + "\n\n"
        
        # Cr√©er le prompt final
        enhanced_prompt = f"""{raw_text_section}{spelling_errors_section}{price_errors_section}

{consistency_prompt.format(vision_result=vision_result, current_date=current_date)}"""
        
        msg = ChatMessage(
            role=MessageRole.USER,
            blocks=[
                TextBlock(text=enhanced_prompt),
                ImageBlock(image=self._last_image_data),
            ],
        )
        
        response = self.llm.chat(messages=[msg])
        result = str(response)
        
        # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
        if result.startswith("assistant:"):
            result = result[len("assistant:"):].strip()
        
        # Stocker les erreurs pour une utilisation ult√©rieure dans analyze_compliance
        self.spelling_errors = spelling_errors
        self.price_errors = price_errors
            
        # Sauvegarder le r√©sultat
        self.output_saver.save_consistency_check(result)
            
        return result

    def verify_dates(self, text: str, **kwargs) -> dict:
        """
        V√©rifie les dates mentionn√©es dans le texte et leur coh√©rence.
        D√©tecte les incoh√©rences entre jours de la semaine et dates.
        
        Args:
            text: Le texte √† analyser
            
        Returns:
            dict: R√©sultat de l'analyse des dates
        """
        print("üîç V√©rification des dates dans le texte")
        
        # R√©cup√©rer la date actuelle
        current_date = datetime.now()
        
        # Ann√©e en cours pour v√©rification des dates
        current_year = 2025
        
        # Dictionnaire normalisant les jours de la semaine
        jours_semaine = {
            'lundi': 0, 'mardi': 1, 'mercredi': 2, 'jeudi': 3, 
            'vendredi': 4, 'samedi': 5, 'dimanche': 6
        }
        
        # Jours avec accents
        jours_semaine_accents = {
            'lundi': 0, 'mardi': 1, 'mercredi': 2, 'jeudi': 3, 
            'vendredi': 4, 'samedi': 5, 'dimanche': 6
        }
        
        # Map des nombres en jours
        map_numero_jour = {
            0: "lundi", 1: "mardi", 2: "mercredi", 3: "jeudi",
            4: "vendredi", 5: "samedi", 6: "dimanche"
        }
        
        # --- NOUVELLE LOGIQUE POUR DATES EN TOUTES LETTRES ET PLAGES ---
        mois_fr = [
            "janvier", "f√©vrier", "fevrier", "mars", "avril", "mai", "juin", "juillet", "ao√ªt", "aout", "septembre", "octobre", "novembre", "d√©cembre", "decembre"
        ]
        mois_map = {m: i+1 for i, m in enumerate([
            "janvier", "f√©vrier", "mars", "avril", "mai", "juin", "juillet", "ao√ªt", "septembre", "octobre", "novembre", "d√©cembre"
        ])}
        mois_map["fevrier"] = 2
        mois_map["aout"] = 8
        mois_map["decembre"] = 12
        
        # Chercher les jours list√©s (ex: "vendredi et samedi")
        jours_regex = r"(lundi|mardi|mercredi|jeudi|vendredi|samedi|dimanche)(?:\s*et\s*(lundi|mardi|mercredi|jeudi|vendredi|samedi|dimanche))*"
        jours_matches = re.findall(jours_regex, text, flags=re.IGNORECASE)
        jours_list = []
        for match in jours_matches:
            jours_list.extend([j for j in match if j])
        jours_list = [j.lower() for j in jours_list if j]
        
        # Chercher les dates en toutes lettres (ex: "27 septembre", "28 septembre")
        date_lettres_regex = r"(\d{1,2})\s*(janvier|f√©vrier|fevrier|mars|avril|mai|juin|juillet|ao√ªt|aout|septembre|octobre|novembre|d√©cembre|decembre)"
        date_lettres_matches = re.findall(date_lettres_regex, text, flags=re.IGNORECASE)
        dates_list = []
        for jour_num, mois in date_lettres_matches:
            mois_num = mois_map[mois.lower()]
            dates_list.append((int(jour_num), mois_num, mois))
        
        # Si on a autant de jours que de dates, on les associe dans l'ordre
        couples = []
        if len(jours_list) == len(dates_list) and len(jours_list) > 0:
            for i in range(len(jours_list)):
                couples.append((jours_list[i], dates_list[i]))
        # Si un seul mois pour plusieurs jours/dates, on fait toutes les combinaisons
        elif len(jours_list) > 0 and len(dates_list) > 0:
            for jour in jours_list:
                for date in dates_list:
                    couples.append((jour, date))
        # Sinon, on continue avec la logique classique
        
        # V√©rifier la coh√©rence pour chaque couple jour/date
        date_errors = []
        for jour, (jour_num, mois_num, mois_nom) in couples:
            try:
                date_obj = datetime(current_year, mois_num, jour_num)
                weekday_num = date_obj.weekday()
                mentioned_weekday_num = jours_semaine[jour.lower()]
                if weekday_num != mentioned_weekday_num:
                    correct_day = map_numero_jour[weekday_num]
                    date_errors.append({
                        "date": f"{jour_num} {mois_nom}",
                        "stated_day": jour,
                        "correct_day": correct_day,
                        "description": f"Le {jour} {jour_num} {mois_nom} {current_year} est un {correct_day}, pas un {jour}."
                    })
                if date_obj.date() < current_date.date():
                    date_errors.append({
                        "date": f"{jour_num} {mois_nom}",
                        "type": "expired",
                        "description": f"La date {jour_num} {mois_nom} {current_year} est d√©j√† pass√©e (date actuelle: {current_date.strftime('%d/%m/%Y')})."
                    })
            except Exception as e:
                date_errors.append({
                    "date": f"{jour_num} {mois_nom}",
                    "stated_day": jour,
                    "error": str(e),
                    "description": f"Erreur d'analyse de date: {str(e)}"
                })
        # --- FIN NOUVELLE LOGIQUE ---
        
        # Sauvegarder les erreurs pour utilisation ailleurs
        self.weekday_errors = date_errors
        
        # R√©sultat de l'analyse
        result = {
            "dates_found": couples,
            "weekday_errors": date_errors,
            "total_errors": len(date_errors)
        }
        
        if date_errors:
            error_descriptions = "\n".join([f"- {err['description']}" for err in date_errors])
            result["summary"] = f"‚ö†Ô∏è {len(date_errors)} incoh√©rence(s) d√©tect√©e(s) dans les dates:\n{error_descriptions}"
        else:
            result["summary"] = "‚úì Aucune incoh√©rence d√©tect√©e dans les dates."
        
        # Sauvegarder le r√©sultat
        if hasattr(self, 'output_saver'):
            self.output_saver.save_output('dates_verification', result)
        
        return result

    def search_legislation(self, vision_result: str) -> str:
        """
        Recherche la l√©gislation applicable
        Args:
            vision_result: R√©sultat de l'analyse visuelle
        Returns:
            str: L√©gislation applicable
        """
        print("\nüîç Recherche de l√©gislation...")
        print(f"Vision result utilis√© pour la recherche: {vision_result[:200]}...")
        
        try:
            # Rechercher dans la base de connaissances
            raw_legislation = self.raptor.search(vision_result)
            print(f"\nL√©gislation brute trouv√©e: {raw_legislation[:200]}...")
            
            # Stocker la l√©gislation brute
            self.legislation = raw_legislation
            
            # Utiliser le query engine pour synth√©tiser la r√©ponse
            query = f"""Analyser et synth√©tiser la l√©gislation suivante dans le contexte de cette publicit√© :
            
            CONTEXTE PUBLICITAIRE :
            {vision_result}
            
            L√âGISLATION TROUV√âE :
            {raw_legislation}
            """
            
            synthesis = self.raptor.query(query)
            print(f"\nSynth√®se de la l√©gislation: {synthesis[:200]}...")
            
            self.output_saver.save_legislation(synthesis)
            
            return synthesis
            
        except Exception as e:
            print(f"\n‚ùå Erreur lors de la recherche de l√©gislation: {str(e)}")
            # En cas d'erreur, utiliser la l√©gislation brute si disponible
            if raw_legislation:
                return raw_legislation
            raise

    def get_clarifications(self, questions_text: str) -> str:
        """
        Obtient des clarifications sp√©cifiques en analysant l'image
        Args:
            questions_text: Questions sp√©cifiques n√©cessitant des clarifications
        Returns:
            str: R√©ponses aux questions de clarification
        """
        print("\n‚ùì Obtention des clarifications...")
        
        if not self.vision_result or not self.legislation:
            raise ValueError("L'analyse visuelle et la recherche de l√©gislation doivent √™tre effectu√©es d'abord")
        
        # Initialiser l'historique des clarifications si n√©cessaire
        if not hasattr(self, '_clarifications_history'):
            self._clarifications_history = set()
        
        # V√©rifier si la question a d√©j√† √©t√© pos√©e
        if questions_text in self._clarifications_history:
            print("‚ö†Ô∏è Cette clarification a d√©j√† √©t√© demand√©e")
            return "Cette question a d√©j√† √©t√© pos√©e. Veuillez demander des clarifications sur d'autres aspects ou passer √† l'analyse de conformit√©."
        
        # Ajouter la question √† l'historique
        self._clarifications_history.add(questions_text)
        
        # Cr√©er le message multimodal avec l'image
        msg = ChatMessage(
            role=MessageRole.USER,
            blocks=[
                TextBlock(text=clarifications_prompt.format(questions_text=questions_text)),
                ImageBlock(image=self._last_image_data),
            ],
        )
        
        print("\nEnvoi de l'image et des questions au LLM...")
        response = self.llm.chat(messages=[msg])
        result = str(response)
        
        # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
        if result.startswith("assistant:"):
            result = result[len("assistant:"):].strip()
        
        self.output_saver.save_clarifications(result)
        
        return result

    def analyze_compliance(self, 
                        vision_result: str = None, 
                        consistency_result: str = None, 
                        legislation_result: str = None,
                        product_logo_analysis: str = None,
                        dates_verification: dict = None,
                        raw_text: str = None,
                        **kwargs) -> str:
        """
        Analyse la conformit√© de la publicit√© en fonction des diff√©rentes analyses
        
        Args:
            vision_result: R√©sultat de l'analyse visuelle
            consistency_result: R√©sultat de la v√©rification de coh√©rence
            legislation_result: R√©sultat de la recherche de l√©gislation
            product_logo_analysis: R√©sultat de l'analyse de coh√©rence produit/logo
            dates_verification: R√©sultat de la v√©rification des dates (format dictionnaire)
            raw_text: Texte brut extrait de l'image
            
        Returns:
            str: Rapport de conformit√©
        """
        
        # R√©cup√©rer les r√©sultats d'analyse pr√©c√©dents si non fournis
        if not vision_result and hasattr(self, 'vision_result'):
            vision_result = self.vision_result
            
        if not consistency_result and hasattr(self, 'consistency_result'):
            consistency_result = self.consistency_result
            
        if not legislation_result and hasattr(self, 'legislation_result'):
            legislation_result = self.legislation_result
            
        if not product_logo_analysis and hasattr(self, 'product_logo_analysis'):
            product_logo_analysis = self.product_logo_analysis
            
        if not dates_verification and hasattr(self, 'weekday_errors'):
            dates_verification = {
                "weekday_errors": self.weekday_errors,
                "total_errors": len(self.weekday_errors) if self.weekday_errors else 0
            }
            
        if not raw_text and hasattr(self, 'raw_text'):
            raw_text = self.raw_text
            
        # Initialiser toutes les variables utilis√©es dans le prompt pour √©viter les erreurs Python
        date_info = ""
        price_errors_info = ""
        weekday_errors_info = ""
        price_errors_summary = ""
        date_errors_summary = ""
        weekday_errors_summary = ""
        non_transformed_products = False
        products_list = []

        # Liste compl√®te des mentions l√©gales nutritionnelles PNNS √† surveiller
        pnns_mentions = [
            "mangerbouger.fr",
            "pour votre sant√©, mangez au moins cinq fruits et l√©gumes par jour",
            "pour votre sant√©, √©vitez de manger trop gras, trop sucr√©, trop sal√©",
            "pour votre sant√©, pratiquez une activit√© physique r√©guli√®re",
            "pour votre sant√©, √©vitez de grignoter entre les repas",
            "pour votre sant√©, √©vitez de consommer trop de sel",
            "pour votre sant√©, limitez les produits sucr√©s",
            "pour votre sant√©, limitez les produits gras",
            "pour votre sant√©, limitez les produits sal√©s",
            "pour votre sant√©, limitez la consommation d'alcool"
        ]

        # Texte √† analyser pour la mention et les produits : raw_text si possible, sinon vision_result
        texte_a_analyser = raw_text if raw_text and not raw_text.startswith('ERREUR') else vision_result if vision_result else ""

        # V√©rifier la pr√©sence d'au moins une mention PNNS dans le texte analys√©
        mentions_pnns_trouvees = [m for m in pnns_mentions if m in texte_a_analyser.lower()]
        mention_pnns_presente = len(mentions_pnns_trouvees) > 0

        # D√©tection des produits transform√©s et non transform√©s
        produits_transformes = False
        tous_non_transformes = False
        produits_detectes = []
        if hasattr(self, 'logo_product_matcher') and texte_a_analyser:
            products = self.logo_product_matcher.extract_products_from_text(texte_a_analyser)
            produits_detectes = products
            if products:
                tous_non_transformes = self.logo_product_matcher.is_non_transformed_product(products)
                # On consid√®re qu'il y a des produits transform√©s si la liste n'est pas tous non transform√©s
                produits_transformes = not tous_non_transformes

        # Liste des non-conformit√©s sp√©cifiques √† ajouter
        non_conformites = []
        # Cas 1 : au moins un produit transform√©, mention PNNS absente
        if produits_transformes and not mention_pnns_presente:
            non_conformites.append(
                "Absence de mention l√©gale nutritionnelle obligatoire (PNNS) alors que des produits transform√©s sont pr√©sents."
            )
        # Cas 2 : tous non transform√©s, mention PNNS pr√©sente
        if tous_non_transformes and mention_pnns_presente:
            produits_str = ", ".join(produits_detectes) if produits_detectes else "(non d√©tect√©s)"
            non_conformites.append(
                f"Non-conformit√© : la mention l√©gale nutritionnelle (PNNS) est pr√©sente alors qu'aucun produit transform√© n'est d√©tect√© (ex : {produits_str}). Cette mention ne doit pas figurer pour des produits non transform√©s."
            )
        # Cas 3 : mixte (au moins un transform√© et un non transform√©), la mention PNNS est obligatoire, ne pas signaler la pr√©sence
        # (d√©j√† couvert par la logique ci-dessus)

        # V√©rification de la pr√©sence du num√©ro RCS et du site internet dans le texte analys√©
        rcs_present = bool(re.search(r"\bRCS\b", texte_a_analyser, re.IGNORECASE))
        site_present = bool(re.search(r"\bhttps?://|www\.[a-z0-9\-]+\.[a-z]{2,}\b", texte_a_analyser, re.IGNORECASE))
        # Exclure www.mangerbouger.fr du site internet de l'entreprise
        site_present = site_present and not re.search(r"www\.mangerbouger\.fr", texte_a_analyser, re.IGNORECASE)
        # Signaler explicitement l'absence de RCS et/ou de site internet
        if not rcs_present:
            non_conformites.append("Absence de num√©ro RCS : la publicit√© doit comporter le num√©ro RCS de l'entreprise.")
        if not site_present:
            non_conformites.append("Absence de site internet de l'entreprise : aucun site internet sp√©cifique √† l'annonceur n'est mentionn√©.")

        # --- Point d'entr√©e pour la v√©rification avanc√©e via RAG ---
        if legislation_result:
            rag_non_conformities = self.check_rag_legislation(legislation_result, texte_a_analyser, produits_detectes)
            non_conformites.extend(rag_non_conformities)
        # --- Fin point d'entr√©e RAG ---

        # Prompt de base pour l'analyse de conformit√©
        prompt = f"""Analyse compl√®te de la conformit√© de cette publicit√© selon la l√©gislation publicitaire:

DONN√âES D'ANALYSE VISUELLE:
{vision_result}

V√âRIFICATION DE COH√âRENCE:
{consistency_result}

L√âGISLATION APPLICABLE:
{legislation_result}

ANALYSE DE COH√âRENCE PRODUIT/LOGO:
{product_logo_analysis}

{date_info}
{price_errors_info}
{weekday_errors_info}

TEXTE BRUT EXTRAIT:
{raw_text if raw_text else "Non disponible"}

{price_errors_summary}
{date_errors_summary}
{weekday_errors_summary}

RAPPEL IMPORTANT:
- NE PAS recommander inutilement d'ajouter une adresse pour l'√©tablissement si ce n'est pas obligatoire
- L'adresse de l'√©tablissement N'EST PAS OBLIGATOIRE pour les publicit√©s standards
- RETIRER toute recommandation d'ajout d'adresse qui ne soit pas l√©galement requise
- LE NUM√âRO DE T√âL√âPHONE N'EST PAS OBLIGATOIRE pour les publicit√©s standards
- NE PAS inclure de section "RECOMMANDATIONS" dans le rapport final
- Se concentrer UNIQUEMENT sur les non-conformit√©s l√©gales r√©elles
- Pour les viandes, les √©toiles (‚òÖ,‚òÜ,‚ú©,‚ú™) indiquent la qualit√© de la viande et NE SONT PAS des ast√©risques n√©cessitant un renvoi
- V√âRIFIER ATTENTIVEMENT les mentions d'origine des produits:
  * "p√™ch√© en Loire Atlantique" ou similaire pour des produits de viande = NON-CONFORMIT√â MAJEURE
  * "Le Porc Fran√ßais" pour des produits qui ne sont pas du porc = NON-CONFORMIT√â MAJEURE 
  * "Le B≈ìuf Fran√ßais" pour des produits qui ne sont pas du b≈ìuf = NON-CONFORMIT√â MAJEURE
  * Toute incoh√©rence entre l'origine d√©clar√©e et le type de produit = NON-CONFORMIT√â MAJEURE
- POUR LES DATES:
  * NE PAS recommander d'ajouter l'ann√©e aux dates - ce n'est PAS n√©cessaire
  * Pour v√©rifier la coh√©rence des dates sans ann√©e mentionn√©e, utiliser l'ann√©e en cours (2025)
  * V√©rifier UNIQUEMENT la coh√©rence entre jour de la semaine et date (ex: si "Vendredi 12/05" est coh√©rent en 2025)
  * NE PAS consid√©rer l'absence d'ann√©e dans une date comme une non-conformit√©
"""

        # Initialiser la variable prompt_reminder
        prompt_reminder = ""

        # Ajouter l'information sur les produits non transform√©s si d√©tect√©s
        if non_transformed_products:
            produits_detectes = ", ".join(products_list)
            prompt_reminder += f"""
INFORMATION CRITIQUE SUR LES PRODUITS NON TRANSFORM√âS:
- Des produits non transform√©s ont √©t√© d√©tect√©s: {produits_detectes}
- Les produits non transform√©s (viande fra√Æche, poisson frais, fruits et l√©gumes frais) sont EXEMPT√âS de la mention www.mangerbouger.fr
- NE PAS signaler l'absence de mention www.mangerbouger.fr comme une non-conformit√©
- NE PAS recommander d'ajouter la mention www.mangerbouger.fr dans ce cas
"""
        
        # RAPPEL CRITIQUE concernant les erreurs de prix
        if price_errors_info:
            prompt_reminder += """
RAPPEL CRITIQUE SUR LES PRIX:
- CONSID√âRER COMME NON-CONFORMIT√â MAJEURE tout prix apr√®s r√©duction sup√©rieur au prix initial
- INCLURE OBLIGATOIREMENT les erreurs de prix d√©tect√©es dans la liste des non-conformit√©s
- EXPLIQUER avec pr√©cision le calcul correct qui aurait d√ª √™tre fait
"""
        
        # RAPPEL CRITIQUE concernant les erreurs de jours/dates
        if weekday_errors_info or date_info:
            prompt_reminder += """
RAPPEL CRITIQUE SUR LES DATES:
- CONSID√âRER COMME NON-CONFORMIT√â MAJEURE toute incoh√©rence entre date et jour de la semaine
- INCLURE OBLIGATOIREMENT les erreurs de dates d√©tect√©es dans la liste des non-conformit√©s
- SP√âCIFIER le jour correct qui correspond √† chaque date mentionn√©e
- V√âRIFIER LA COH√âRENCE avec l'ann√©e en cours (2025) pour les dates sans ann√©e
- NE PAS recommander d'ajouter l'ann√©e aux dates - ce n'est PAS n√©cessaire
"""
        
        prompt += prompt_reminder
        
        # Ajouter les non-conformit√©s sp√©cifiques dans le prompt final
        if non_conformites:
            prompt += "\n\nNON-CONFORMIT√âS SP√âCIFIQUES D√âTECT√âES :\n"
            for nc in non_conformites:
                prompt += f"- {nc}\n"
        
        # Utiliser le LLM pour analyser la conformit√©
        response = self.llm.complete(prompt)
        result = str(response)
        
        # Supprimer le pr√©fixe "assistant:" s'il est pr√©sent
        if result.startswith("assistant:"):
            result = result[len("assistant:"):].strip()
        
        # Sauvegarder le r√©sultat
        if hasattr(self, 'output_saver'):
            try:
                self.output_saver.save_output('compliance_analysis', result)
            except AttributeError:
                # Utiliser une autre m√©thode de sauvegarde si save_output n'existe pas
                self.output_saver.save_compliance_analysis(result)
        
        return result

    def extract_text_from_image(self, image_path: str, mode: str = "docling", ocr_engine: str = "tesseract") -> str:
        """
        Extrait le texte visible dans une image publicitaire
        
        Args:
            image_path: Chemin vers l'image √† analyser
            mode: Mode d'extraction ('docling', 'pytesseract', 'easyocr')
            ocr_engine: Moteur OCR √† utiliser avec Docling ('tesseract', 'easyocr', 'rapidocr')
            
        Returns:
            str: Texte extrait de l'image
        """
        print(f"\nüî§ Extraction du texte de l'image avec {mode}: {image_path}")
        
        # Configurer les options d'extraction selon le mode
        options = {}
        if mode == "docling":
            try:
                # Options avanc√©es pour l'extraction Docling
                extracted_text = self.text_extractor.extract_text_with_docling(
                    image_path, 
                    ocr_engine=ocr_engine,
                    custom_options=options
                )
            except Exception as e:
                print(f"‚ö†Ô∏è Erreur avec Docling: {str(e)}. Essai d'une m√©thode alternative...")
                # Fallback vers une autre m√©thode
                extracted_text = self.text_extractor.extract_text(image_path, fallback=True)
        elif mode == "pytesseract":
            extracted_text = self.text_extractor.extract_text_with_pytesseract(image_path)
        elif mode == "easyocr":
            extracted_text = self.text_extractor.extract_text_with_easyocr_direct(image_path)
        else:
            print(f"‚ö†Ô∏è Mode {mode} non support√©, utilisation de la m√©thode g√©n√©rique")
            extracted_text = self.text_extractor.extract_text(image_path, fallback=True)
        
        # Si le texte est vide, afficher un avertissement
        if not extracted_text or len(extracted_text.strip()) < 5:
            print("‚ö†Ô∏è Attention: Tr√®s peu ou pas de texte extrait de l'image.")
        else:
            print(f"‚úÖ Texte extrait ({len(extracted_text)} caract√®res)")
            
        # Sauvegarder des m√©tadonn√©es suppl√©mentaires pour l'analyse
        metadata = {
            "mode": mode,
            "ocr_engine": ocr_engine if mode == "docling" else "N/A",
            "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "char_count": len(extracted_text),
            "success": bool(extracted_text and len(extracted_text.strip()) > 5)
        }
        
        # Sauvegarder le r√©sultat dans les sorties
        self.output_saver.save_text_extraction(extracted_text, mode)
        self.extracted_text = extracted_text
        
        return extracted_text 

    def extract_raw_text_with_vision(self, image_path: str) -> str:
        """
        Extrait le texte brut d'une image en utilisant un fallback OCR robuste (Tesseract/EasyOCR)
        Args:
            image_path: Chemin de l'image
        Returns:
            str: Texte brut extrait
        """
        print(f"\nüìù Extraction du texte brut pour l'agent (fallback OCR): {image_path}")
        try:
            # Utiliser l'OCR local (Tesseract/EasyOCR) avec fallback
            raw_text = self.text_extractor.extract_text(image_path, fallback=True)
            if raw_text:
                print("\nüíæ Texte brut sauvegard√© dans le fichier JSON principal")
                return raw_text
            else:
                return "Aucun texte extrait"
        except Exception as e:
            print(f"‚ùå Erreur lors de l'extraction de texte brut: {str(e)}")
            return f"ERREUR: {str(e)}"

    def extract_raw_text_for_agent(self, image_path: str) -> str:
        """
        Extrait le texte brut d'une image publicitaire pour l'agent ReACT
        
        Args:
            image_path: Chemin vers l'image √† analyser
            
        Returns:
            str: Texte brut extrait
        """
        print(f"\nüìù Extraction du texte brut pour l'agent: {image_path}")
        
        try:
            # V√©rifier que l'image existe
            if not os.path.exists(image_path):
                error_msg = f"‚ùå Image non trouv√©e: {image_path}"
                print(error_msg)
                return error_msg
            
            # Initialiser une nouvelle analyse - Important: doit √™tre fait AVANT d'essayer de sauvegarder des r√©sultats
            self.output_saver.start_new_analysis(image_path)
            
            # Utiliser GPT Vision pour l'extraction
            result = self.extract_raw_text_with_vision(image_path)
            
            # V√©rifier que le r√©sultat n'est pas vide
            if not result or len(result.strip()) < 10:
                print("‚ö†Ô∏è Texte extrait trop court ou vide, mais continuons l'analyse")
            
            # Sauvegarder dans les donn√©es de l'analyse
            self.raw_text = result
            
            # Sauvegarder dans l'output_saver
            self.output_saver.save_raw_text(result)
            
            print("‚úÖ Extraction de texte brut r√©ussie")
            return result
            
        except Exception as e:
            error_msg = f"‚ùå Erreur lors de l'extraction du texte brut: {str(e)}"
            print(error_msg)
            # M√™me en cas d'erreur, on continue l'analyse
            print("‚ö†Ô∏è Continuez avec l'analyse visuelle malgr√© l'erreur d'extraction")
            return error_msg 

    def verify_product_logo_consistency(self, vision_result: str = None) -> str:
        """
        V√©rifie la coh√©rence entre les logos et les produits mentionn√©s dans la publicit√©
        
        Args:
            vision_result: R√©sultat de l'analyse visuelle (optionnel)
            
        Returns:
            str: Rapport de v√©rification des coh√©rences logo-produit
        """
        print("\nüîç V√©rification de la coh√©rence entre logos et produits...")
        
        if not vision_result and not self.vision_result:
            raise ValueError("L'analyse visuelle doit √™tre effectu√©e d'abord")
            
        vision_content = vision_result if vision_result else self.vision_result
        
        # Texte complet √† analyser (combinaison de l'analyse visuelle et du texte brut)
        full_text = vision_content
        if hasattr(self, 'raw_text') and self.raw_text:
            full_text = full_text + "\n\n" + self.raw_text
        
        # Extraire les produits et logos mentionn√©s dans le texte
        products = self.logo_product_matcher.extract_products_from_text(full_text)
        logos = self.logo_product_matcher.extract_logos_from_text(full_text)
        
        # V√©rifier la coh√©rence
        inconsistencies = self.logo_product_matcher.check_product_logo_consistency(logos, products)
        self.product_logo_inconsistencies = inconsistencies
        
        # Construire le rapport
        if not inconsistencies:
            result = "V√âRIFICATION PRODUITS/LOGOS : COH√âRENT\n\nAucune incoh√©rence d√©tect√©e entre les logos et les produits mentionn√©s."
            if logos:
                result += f"\n\nLogos d√©tect√©s ({len(logos)}) : {', '.join(logos)}"
            if products:
                result += f"\n\nProduits d√©tect√©s ({len(products)}) : {', '.join(products)}"
        else:
            result = "V√âRIFICATION PRODUITS/LOGOS : NON COH√âRENT\n\nIncoh√©rences d√©tect√©es :\n"
            for i, inconsistency in enumerate(inconsistencies, 1):
                result += f"{i}. Le logo '{inconsistency['logo']}' n'est pas compatible avec les produits suivants : {', '.join(inconsistency['products'])}\n"
                result += f"   ‚Üí Cat√©gories autoris√©es pour ce logo : {', '.join(inconsistency['allowed_categories'])}\n\n"
            
            result += "RECOMMANDATION : Corriger ces incoh√©rences en rempla√ßant les logos par des logos appropri√©s pour les produits concern√©s."
        
        # Sauvegarder le r√©sultat
        self.output_saver.save_product_logo_consistency(result)
        
        return result 

    def check_price_consistency(self, text: str) -> list:
        """
        V√©rifie la coh√©rence des prix et des r√©ductions dans une publicit√©.
        D√©tecte notamment les prix apr√®s r√©duction sup√©rieurs ou √©gaux aux prix initiaux.
        
        Args:
            text: Texte brut extrait de l'image
            
        Returns:
            list: Liste des incoh√©rences de prix d√©tect√©es
        """
        print("\nüí∞ V√©rification de la coh√©rence des prix et r√©ductions...")
        
        if not text:
            return []
            
        # Liste pour stocker les erreurs trouv√©es
        price_errors = []
        
        # Chercher des motifs de prix et de r√©ductions
        import re
        
        # 1. Recherche directe de prix avant/apr√®s r√©duction
        # Format courant: prix initial X‚Ç¨ -> prix r√©duit Y‚Ç¨
        price_pairs = re.findall(r'(\d+[,.]\d+|\d+)(\s*‚Ç¨|\s*EUR|\s*euros?)(?:\s*[-‚Äì‚Äî>‚Üí]+\s*)(\d+[,.]\d+|\d+)(\s*‚Ç¨|\s*EUR|\s*euros?)', text)
        
        for match in price_pairs:
            try:
                # Extraire et normaliser les prix (remplacer virgule par point)
                initial_price = float(match[0].replace(',', '.'))
                reduced_price = float(match[2].replace(',', '.'))
                
                # V√©rifier si le prix r√©duit est sup√©rieur ou √©gal au prix initial
                if reduced_price >= initial_price:
                    error_info = {
                        "type": "prix_sup√©rieur",
                        "prix_initial": initial_price,
                        "prix_r√©duit": reduced_price,
                        "diff√©rence": reduced_price - initial_price,
                        "pourcentage": 100 * (reduced_price - initial_price) / initial_price if initial_price > 0 else 0,
                        "texte_original": f"{match[0]}{match[1]} -> {match[2]}{match[3]}"
                    }
                    price_errors.append(error_info)
                    print(f"‚ö†Ô∏è Prix incoh√©rent: {error_info['texte_original']} - Le prix apr√®s r√©duction est plus √©lev√© que le prix initial")
            except ValueError:
                # Ignorer si la conversion en float √©choue
                continue
        
        # 2. Recherche de prix avec pourcentage de r√©duction explicite
        # Format courant: prix X‚Ç¨ -Y% -> prix Z‚Ç¨
        discount_patterns = re.findall(r'(\d+[,.]\d+|\d+)(\s*‚Ç¨|\s*EUR|\s*euros?)\s*[-‚Äì‚Äî]\s*(\d+)(\s*%)\s*(?:[-‚Äì‚Äî>‚Üí]+)\s*(\d+[,.]\d+|\d+)(\s*‚Ç¨|\s*EUR|\s*euros?)', text)
        
        for match in discount_patterns:
            try:
                initial_price = float(match[0].replace(',', '.'))
                discount_pct = float(match[2])
                final_price = float(match[4].replace(',', '.'))
                
                # Calculer le prix r√©duit attendu
                expected_price = round(initial_price * (1 - discount_pct/100), 2)
                
                # Tol√©rance d'arrondi (1 centime)
                tolerance = 0.01
                
                # V√©rifier si le prix affich√© est sup√©rieur au prix initial
                if final_price >= initial_price:
                    error_info = {
                        "type": "prix_sup√©rieur_avec_r√©duction",
                        "prix_initial": initial_price,
                        "pourcentage_r√©duction": discount_pct,
                        "prix_affich√©": final_price,
                        "prix_calcul√©": expected_price,
                        "diff√©rence": final_price - initial_price,
                        "texte_original": f"{match[0]}{match[1]} -{match[2]}% -> {match[4]}{match[5]}"
                    }
                    price_errors.append(error_info)
                    print(f"‚ö†Ô∏è Prix incoh√©rent: {error_info['texte_original']} - Le prix apr√®s r√©duction est plus √©lev√© que le prix initial")
                
                # V√©rifier si le prix affich√© correspond au calcul de la r√©duction
                elif abs(final_price - expected_price) > tolerance:
                    error_info = {
                        "type": "calcul_incorrect",
                        "prix_initial": initial_price,
                        "pourcentage_r√©duction": discount_pct,
                        "prix_affich√©": final_price,
                        "prix_calcul√©": expected_price,
                        "diff√©rence": final_price - expected_price,
                        "texte_original": f"{match[0]}{match[1]} -{match[2]}% -> {match[4]}{match[5]}"
                    }
                    price_errors.append(error_info)
                    print(f"‚ö†Ô∏è Calcul de r√©duction incorrect: {error_info['texte_original']} - Le prix devrait √™tre {expected_price}‚Ç¨")
            except ValueError:
                continue
        
        # 3. Recherche de prix barr√©s suivis de prix r√©duits
        # Format courant: prix barr√© X‚Ç¨ prix Y‚Ç¨
        # D√©tecter les mots sugg√©rant un prix barr√©: ancien prix, avant, √©tait √†, etc.
        barred_price_patterns = [
            r'(?:ancien\s+prix|prix\s+normal|avant|√©tait\s+√†|prix\s+habituel)(?:\s*:)?\s*(\d+[,.]\d+|\d+)(\s*‚Ç¨|\s*EUR|\s*euros?)(?:[^‚Ç¨]*?)(\d+[,.]\d+|\d+)(\s*‚Ç¨|\s*EUR|\s*euros?)',
            r'(\d+[,.]\d+|\d+)(\s*‚Ç¨|\s*EUR|\s*euros?)(?:\s*(?:au lieu de|barr√©|remplac√© par))(?:[^‚Ç¨]*?)(\d+[,.]\d+|\d+)(\s*‚Ç¨|\s*EUR|\s*euros?)'
        ]
        
        for pattern in barred_price_patterns:
            matches = re.findall(pattern, text, re.IGNORECASE)
            for match in matches:
                try:
                    # L'ordre peut varier selon le pattern, d√©terminer quel prix est l'initial et lequel est le r√©duit
                    prices = [float(match[0].replace(',', '.')), float(match[2].replace(',', '.'))]
                    currencies = [match[1], match[3]]
                    
                    # Dans le premier pattern, le prix initial est le premier; dans le second, c'est le deuxi√®me
                    if pattern == barred_price_patterns[0]:
                        initial_price, reduced_price = prices
                        initial_currency, reduced_currency = currencies
                    else:
                        reduced_price, initial_price = prices
                        reduced_currency, initial_currency = currencies
                    
                    # V√©rifier si le prix r√©duit est sup√©rieur ou √©gal au prix initial
                    if reduced_price >= initial_price:
                        error_info = {
                            "type": "prix_barr√©_incoh√©rent",
                            "prix_initial": initial_price,
                            "prix_r√©duit": reduced_price,
                            "diff√©rence": reduced_price - initial_price,
                            "pourcentage": 100 * (reduced_price - initial_price) / initial_price if initial_price > 0 else 0,
                            "texte_original": match[0] + match[1] + "..." + match[2] + match[3]
                        }
                        price_errors.append(error_info)
                        print(f"‚ö†Ô∏è Prix barr√© incoh√©rent: le prix r√©duit {reduced_price}{reduced_currency} est sup√©rieur au prix initial {initial_price}{initial_currency}")
                except ValueError:
                    continue
        
        # R√©sum√© des r√©sultats
        if price_errors:
            print(f"‚ö†Ô∏è {len(price_errors)} incoh√©rences de prix d√©tect√©es")
        else:
            print("‚úÖ Aucune incoh√©rence de prix d√©tect√©e")
            
        return price_errors 

    def check_rag_legislation(self, legislation_text, ad_text, products):
        """
        Analyse la l√©gislation extraite du RAG et d√©tecte les non-conformit√©s sp√©cifiques enrichies.
        Args:
            legislation_text (str): Texte de la l√©gislation extraite (RAG)
            ad_text (str): Texte de la publicit√© √† analyser
            products (list): Liste des produits d√©tect√©s
        Returns:
            list: Liste de non-conformit√©s d√©tect√©es
        """
        non_conformities = []
        if not legislation_text or not ad_text:
            return non_conformities

        import re

        # 1. Mentions obligatoires globales
        mentions_obligatoires = re.findall(r"mention obligatoire ?: ([^\n\r]+)", legislation_text, re.IGNORECASE)
        for mention in mentions_obligatoires:
            if mention.lower() not in ad_text.lower():
                non_conformities.append(f"Mention l√©gale obligatoire absente : '{mention}'")

        # 2. Mentions interdites globales
        mentions_interdites = re.findall(r"mention interdite ?: ([^\n\r]+)", legislation_text, re.IGNORECASE)
        for mention in mentions_interdites:
            if mention.lower() in ad_text.lower():
                non_conformities.append(f"Mention l√©gale interdite pr√©sente : '{mention}'")

        # 3. Mentions obligatoires conditionnelles par produit
        # Exemple de pattern : "mention obligatoire pour (.+) : (.+)"
        cond_obligatoires = re.findall(r"mention obligatoire pour ([^:]+) ?: ([^\n\r]+)", legislation_text, re.IGNORECASE)
        for condition, mention in cond_obligatoires:
            for prod in products:
                if condition.lower() in prod.lower() and mention.lower() not in ad_text.lower():
                    non_conformities.append(f"Mention obligatoire pour '{condition}' absente alors que le produit '{prod}' est pr√©sent : '{mention}'")

        # 4. Mentions interdites conditionnelles par produit
        cond_interdites = re.findall(r"mention interdite pour ([^:]+) ?: ([^\n\r]+)", legislation_text, re.IGNORECASE)
        for condition, mention in cond_interdites:
            for prod in products:
                if condition.lower() in prod.lower() and mention.lower() in ad_text.lower():
                    non_conformities.append(f"Mention interdite pour '{condition}' pr√©sente alors que le produit '{prod}' est pr√©sent : '{mention}'")

        # 5. Mentions √† formuler exactement
        exact_mentions = re.findall(r"mention exacte ?: ([^\n\r]+)", legislation_text, re.IGNORECASE)
        for mention in exact_mentions:
            if mention.lower() not in ad_text.lower():
                non_conformities.append(f"La mention obligatoire doit √™tre formul√©e exactement ainsi : '{mention}'")

        # 6. (Extension possible : position, taille, couleur, etc. √† partir de la vision)
        # √Ä impl√©menter selon les besoins et les capacit√©s de la vision

        return non_conformities 